import streamlit as st
from datetime import datetime
from multi_agent_system import create_interview_graph, load_topics_from_csv
from logger import InterviewLogger, set_logger, clear_logger, get_logger
import os

# Streamlit UI
st.set_page_config(page_title="AIé¢æ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", page_icon="ğŸ’¼", layout="wide")

st.title("ğŸ’¼ å¾“æ¥­å“¡çŸ¥è­˜è©•ä¾¡é¢æ¥")
st.markdown("ä¼æ¥­ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹å¾“æ¥­å“¡ã®çŸ¥è­˜ã‚’è©•ä¾¡ã™ã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'interview_started' not in st.session_state:
    st.session_state.interview_started = False
if 'session_id' not in st.session_state:
    st.session_state.session_id = None
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'interview_ended' not in st.session_state:
    st.session_state.interview_ended = False
if 'state' not in st.session_state:
    st.session_state.state = None
if 'graph' not in st.session_state:
    st.session_state.graph = None
if 'logger' not in st.session_state:
    st.session_state.logger = None
if 'last_processed_input' not in st.session_state:
    st.session_state.last_processed_input = None
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'feedback' not in st.session_state:
    st.session_state.feedback = None
if 'feedback_tokens' not in st.session_state:
    st.session_state.feedback_tokens = 0
if 'execution_logs' not in st.session_state:
    st.session_state.execution_logs = []  # å„å¿œç­”ã®å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("é¢æ¥è¨­å®š")
    
    if not st.session_state.interview_started:
        # LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®è¡¨ç¤º
        llm_provider = os.getenv("LLM_PROVIDER", "openai").upper()
        st.info(f"ğŸ¤– LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: **{llm_provider}**")
        
        # ãƒˆãƒ”ãƒƒã‚¯ã®èª­ã¿è¾¼ã¿ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        topics_file = st.text_input("ãƒˆãƒ”ãƒƒã‚¯CSVãƒ•ã‚¡ã‚¤ãƒ«", value="topics.csv")
        
        if os.path.exists(topics_file):
            topics = load_topics_from_csv(topics_file)
            st.success(f"âœ… {len(topics)}ä»¶ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            
            # ãƒ†ãƒ¼ãƒåˆ¥ã«ãƒˆãƒ”ãƒƒã‚¯ã‚’æ•´ç†
            themes_dict = {}
            for topic in topics:
                theme = topic.get('theme', 'ãã®ä»–')
                if theme not in themes_dict:
                    themes_dict[theme] = []
                themes_dict[theme].append(topic)
            
            # ãƒ„ãƒªãƒ¼ãƒ“ãƒ¥ãƒ¼ã®è¡¨ç¤º
            with st.expander(f"ğŸ“‹ ãƒˆãƒ”ãƒƒã‚¯æ§‹é€  ({len(themes_dict)}ãƒ†ãƒ¼ãƒ)", expanded=False):
                for theme_idx, theme in enumerate(sorted(themes_dict.keys()), 1):
                    # æŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ãªãƒ†ãƒ¼ãƒã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
                    show_theme = st.checkbox(f"ğŸ¯ {theme} ({len(themes_dict[theme])}ãƒˆãƒ”ãƒƒã‚¯)", key=f"theme_{theme_idx}", value=False)
                    
                    if show_theme:
                        for idx, topic in enumerate(themes_dict[theme], 1):
                            # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆä»˜ãã®ãƒˆãƒ”ãƒƒã‚¯å
                            st.markdown(f"&nbsp;&nbsp;&nbsp;&nbsp;**{idx}. {topic.get('topic', 'N/A')}**")
                            
                            # ã•ã‚‰ã«ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã•ã‚ŒãŸä¾‹ç¤ºè³ªå•
                            example_questions = topic.get('example_questions', [])
                            if example_questions:
                                for q_idx, question in enumerate(example_questions, 1):
                                    st.caption(f"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;â€¢ {question}")
                            
                            # ãƒˆãƒ”ãƒƒã‚¯é–“ã®ã‚¹ãƒšãƒ¼ã‚¹
                            if idx < len(themes_dict[theme]):
                                st.write("")
                    
                    # ãƒ†ãƒ¼ãƒé–“ã®ã‚¹ãƒšãƒ¼ã‚¹
                    if theme_idx < len(themes_dict):
                        st.write("")
        else:
            st.warning("âš ï¸ ãƒˆãƒ”ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            topics = load_topics_from_csv(topics_file)
        
        max_iterations = st.slider("ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã®æœ€å¤§ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—æ•°", 1, 5, 2)
        max_judge_retries = st.slider("Judge Agentã®æœ€å¤§å†è©¦è¡Œå›æ•°", 0, 5, 2, 
                                       help="ç„¡åŠ¹ãªå›ç­”ã«å¯¾ã—ã¦Judge AgentãŒå†è©¦è¡Œã‚’æ±‚ã‚ã‚‹å›æ•°ã€‚0ã«è¨­å®šã™ã‚‹ã¨æ¬¡ã®è³ªå•ã«ç›´æ¥ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        
        if st.button("é¢æ¥ã‚’é–‹å§‹", type="primary"):
            with st.spinner("ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­..."):
                # ä¸€æ„ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆ
                st.session_state.session_id = f"interview_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                
                # ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
                st.session_state.logger = InterviewLogger(st.session_state.session_id)
                set_logger(st.session_state.logger)
                st.session_state.logger.text_logger.info("Interview session initialized")
                
                # çŠ¶æ…‹ã®åˆæœŸåŒ–
                st.session_state.state = {
                    "topics": topics,
                    "current_topic_index": 0,
                    "current_topic": {},
                    "topic_iteration_count": 0,
                    "max_iterations_per_topic": max_iterations,
                    "judge_retry_count": 0,
                    "max_judge_retries": max_judge_retries,
                    "current_question": "",
                    "user_answer": "",
                    "security_passed": False,
                    "security_feedback": "",
                    "topic_depth_sufficient": False,
                    "topic_feedback": "",
                    "interview_complete": False,
                    "conversation_history": [],
                    "current_agent": "",
                    "total_tokens": 0,
                    "last_message_tokens": 0,
                    "waiting_for_user_input": False  # ä¸­æ–­ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ç½®ãæ›ãˆã‚‰ã‚Œã¾ã™
                }
                
                # ä¸­æ–­ç”¨ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ã‚¿ãƒ¼ä»˜ãã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
                st.session_state.graph = create_interview_graph()
                
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ°¸ç¶šåŒ–ç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰è¨­å®š
                config = {"configurable": {"thread_id": st.session_state.session_id}}
                
                # ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œã‚’é–‹å§‹ - HITLï¼ˆä¸­æ–­ï¼‰ã«åˆ°é”ã™ã‚‹ã¾ã§å®Ÿè¡Œ
                # ã‚°ãƒ©ãƒ•ãƒ•ãƒ­ãƒ¼: START â†’ topic_agent â†’ human_input_node (INTERRUPT)
                for chunk in st.session_state.graph.stream(st.session_state.state, config):
                    # å„ãƒãƒ¼ãƒ‰ã®å‡ºåŠ›ã‚’å‡¦ç†
                    for node_name, node_output in chunk.items():
                        st.session_state.state.update(node_output)
                
                # ã“ã®æ™‚ç‚¹ã§ã€ã‚°ãƒ©ãƒ•ã¯human_input_nodeã§ä¸­æ–­ã•ã‚Œã¦ã„ã¾ã™
                # æœ€åˆã®è³ªå•ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™
                
                # æœ€åˆã®è³ªå•ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                if st.session_state.state.get("current_question"):
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": st.session_state.state["current_question"],
                        "agent": st.session_state.state.get("current_agent", "Topic Agent"),
                        "tokens": st.session_state.state.get("last_message_tokens", 0)
                    })
                
                st.session_state.interview_started = True
                st.rerun()
    
    else:
        st.success("âœ… é¢æ¥é€²è¡Œä¸­")
        
        # é€²æ—çŠ¶æ³ã®è¡¨ç¤º
        if st.session_state.state:
            current_idx = st.session_state.state["current_topic_index"]
            total_topics = len(st.session_state.state["topics"])
            st.progress((current_idx + 1) / total_topics)
            st.write(f"ãƒˆãƒ”ãƒƒã‚¯ {current_idx + 1} / {total_topics}")
            
            if st.session_state.state.get("current_topic"):
                st.info(f"**ç¾åœ¨ã®ãƒˆãƒ”ãƒƒã‚¯:**\n{st.session_state.state['current_topic'].get('topic', 'N/A')}")
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡
            total_tokens = st.session_state.state.get("total_tokens", 0)
            st.metric("ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³åˆè¨ˆ", total_tokens)
        
        st.divider()
        
        # é¢æ¥çµ‚äº†ãƒœã‚¿ãƒ³ã¯ã€ã¾ã çµ‚äº†ã—ã¦ã„ãªã„&ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆä¸­ã§ãªã„å ´åˆã®ã¿è¡¨ç¤º
        if not st.session_state.interview_ended and not st.session_state.get('generating_feedback', False):
            if st.button("é¢æ¥ã‚’çµ‚äº†ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—", type="secondary", key="end_interview_btn"):
                # å‡¦ç†å‰ã«çŠ¶æ…‹ã‚’å†ç¢ºèªï¼ˆç«¶åˆçŠ¶æ…‹ã‚’é˜²ãï¼‰
                if st.session_state.interview_ended or st.session_state.get('generating_feedback', False) or st.session_state.get('feedback'):
                    st.rerun()
                    
                st.session_state.generating_feedback = True
                
                try:
                    with st.spinner("åŒ…æ‹¬çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆä¸­..."):
                        # ãƒ‡ãƒãƒƒã‚°ç”¨ã®ãƒ­ã‚°
                        if st.session_state.logger:
                            st.session_state.logger.text_logger.info("Button clicked: End Interview & Get Feedback")
                        
                        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰è¨­å®š
                        config = {"configurable": {"thread_id": st.session_state.session_id}}
                        
                        # ã‚°ãƒ©ãƒ•ãŒä¸­æ–­å¯èƒ½ãªçŠ¶æ…‹ã‹ãƒã‚§ãƒƒã‚¯
                        try:
                            snapshot = st.session_state.graph.get_state(config)
                            # æ¬¡ã®ãƒãƒ¼ãƒ‰ãƒªã‚¹ãƒˆãŒç©ºã®å ´åˆã€ã‚°ãƒ©ãƒ•ã¯æ—¢ã«å®Œäº†ã—ã¦ã„ã¾ã™
                            if not snapshot.next:
                                if st.session_state.logger:
                                    st.session_state.logger.text_logger.warning("Graph already at END state, cannot resume")
                                st.session_state.generating_feedback = False
                                st.rerun()
                        except Exception as e:
                            if st.session_state.logger:
                                st.session_state.logger.text_logger.error(f"Error checking graph state: {e}")
                        
                        # é‡è¦: ã‚°ãƒ©ãƒ•çŠ¶æ…‹ã«interview_completeãƒ•ãƒ©ã‚°ã‚’è¨­å®š
                        # æœ€é©åŒ–: security â†’ topic_guideã‚’çµŒç”±ã›ãšã€
                        # interview_complete=Trueã§topic_guideã‹ã‚‰æ¥ãŸã‚ˆã†ã«çŠ¶æ…‹ã‚’æ›´æ–°
                        # ã“ã‚Œã«ã‚ˆã‚Štopic_guideã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒã™ãã«ãƒ•ãƒ©ã‚°ã‚’ç¢ºèªã—ã¦feedback_agentã«é€²ã¿ã¾ã™
                        
                        # ã¾ãšã€é‡è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¿æŒã™ã‚‹ãŸã‚ã«ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—
                        current_snapshot = st.session_state.graph.get_state(config)
                        current_values = current_snapshot.values
                        
                        # topic_guideãƒãƒ¼ãƒ‰ã¨ã—ã¦å‹•ä½œã—ã€interview_completeãƒ•ãƒ©ã‚°ã§çŠ¶æ…‹ã‚’æ›´æ–°
                        st.session_state.graph.update_state(
                            config,
                            {
                                "interview_complete": True,
                                "topic_depth_sufficient": False,  # interview_completeãŒå„ªå…ˆã•ã‚Œã‚‹ã®ã§é–¢ä¿‚ã‚ã‚Šã¾ã›ã‚“
                                "user_answer": current_values.get("user_answer", ""),  # æ—¢å­˜ã®å›ç­”ã‚’ä¿æŒ
                            },
                            as_node="topic_guide"  # topic_guideãŒè©•ä¾¡ã‚’çµ‚ãˆãŸã‹ã®ã‚ˆã†ã«å‹•ä½œ
                        )
                        
                        # topic_guideã‹ã‚‰å†é–‹ - feedback_agentã«ç›´æ¥ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
                        for chunk in st.session_state.graph.stream(None, config):
                            for node_name, node_output in chunk.items():
                                if isinstance(node_output, dict):
                                    st.session_state.state.update(node_output)
                                    
                                    # feedback_agentã«åˆ°é”ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                                    if node_output.get("current_agent") == "Feedback Agent" or node_name == "feedback_agent":
                                        # ã™ãã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æŠ½å‡º
                                        if node_output.get("current_question"):
                                            st.session_state.feedback = node_output["current_question"]
                                            st.session_state.feedback_tokens = node_output.get("last_message_tokens", 0)
                                            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                                            break
                        
                        if st.session_state.logger:
                            st.session_state.logger.text_logger.info("Graph stream completed successfully")
                        
                        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæŠ½å‡ºã•ã‚ŒãŸã‹ç¢ºèª
                        if not st.session_state.get('feedback'):
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€çµ‚çŠ¶æ…‹ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
                            if st.session_state.state.get("current_question") and st.session_state.state.get("current_agent") in ["Feedback Agent", "ğŸ“ Feedback Agent"]:
                                st.session_state.feedback = st.session_state.state["current_question"]
                                st.session_state.feedback_tokens = st.session_state.state.get("last_message_tokens", 0)
                            else:
                                st.session_state.feedback = "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                                st.session_state.feedback_tokens = 0
                        
                        # é¢æ¥å®Œäº†ã®ãƒ­ã‚°
                        if st.session_state.logger and st.session_state.get('feedback'):
                            total_questions = len([m for m in st.session_state.messages if m["role"] == "assistant"])
                            st.session_state.logger.log_interview_complete(
                                st.session_state.state["current_topic_index"],
                                total_questions
                            )
                        
                        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚ŒãŸå ´åˆã®ã¿çµ‚äº†ã¨ãƒãƒ¼ã‚¯
                        if st.session_state.get('feedback'):
                            st.session_state.interview_ended = True
                        
                finally:
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ•ãƒ©ã‚°ã‚’å¸¸ã«ã‚¯ãƒªã‚¢
                    st.session_state.generating_feedback = False
                    
                st.rerun()
        elif st.session_state.get('generating_feedback', False):
            st.info("â³ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
        
        if st.button("é¢æ¥ã‚’ãƒªã‚»ãƒƒãƒˆ", type="primary"):
            # ãƒªã‚»ãƒƒãƒˆå‰ã«ãƒ­ã‚¬ãƒ¼ã‚’ä¿å­˜ã—ã¦ã‚¯ãƒªã‚¢
            if st.session_state.logger:
                st.session_state.logger.save()
                clear_logger()
            
            st.session_state.interview_started = False
            st.session_state.session_id = None
            st.session_state.messages = []
            st.session_state.interview_ended = False
            st.session_state.state = None
            st.session_state.graph = None
            st.session_state.logger = None
            if 'feedback' in st.session_state:
                del st.session_state.feedback
            st.rerun()

# ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
if st.session_state.interview_started and not st.session_state.interview_ended:
    # ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
            if message["role"] == "assistant" and "agent" in message:
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.caption(f"{message['agent']}")
                with col2:
                    st.caption(f"ğŸª™ {message.get('tokens', 0)} tokens")
            
            st.markdown(message["content"])
            
            # å®Ÿè¡Œãƒ­ã‚°ã®ã‚ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ‡ãƒãƒƒã‚°ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã‚’è¡¨ç¤º
            if message["role"] == "assistant" and "execution_log" in message:
                execution_log = message["execution_log"]
                
                with st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°: Agent Flow", expanded=False):
                    for i, log in enumerate(execution_log, 1):
                        node = log["node"]
                        agent = log["agent"]
                        details = log["details"]
                        
                        # Security Agent
                        if node == "security_agent":
                            status = "âœ… åˆæ ¼" if details.get("passed") else "âŒ ä¸åˆæ ¼"
                            next_step = "â†’ Topic Guide" if details.get("passed") else "â†’ Judge"
                            st.markdown(f"**{i}. ğŸ”’ Security** {status} {next_step}")
                            if not details.get("passed"):
                                st.caption(f"   ç†ç”±: {details.get('feedback', 'N/A')}")
                        
                        # Judge Agent
                        elif node == "judge":
                            action = "å†è©¦è¡Œ" if details.get('action') == 'requesting retry' else "è«¦ã‚ã‚‹"
                            next_step = "â†’ HITL" if details.get('action') == 'requesting retry' else "â†’ Topic Guide"
                            st.markdown(f"**{i}. âš–ï¸ Judge** {action} ({details.get('retry_count', 0)}/{details.get('max_retries', 0)}) {next_step}")
                        
                        # Topic Guide
                        elif node == "topic_guide":
                            depth = "âœ… ååˆ†" if details.get("depth_sufficient") else "âŒ ä¸è¶³"
                            if details.get("depth_sufficient"):
                                next_step = "â†’ æ¬¡ã®ãƒˆãƒ”ãƒƒã‚¯" if details.get('iteration', 0) < details.get('max_iterations', 0) else "â†’ Feedback"
                            else:
                                next_step = "â†’ Probing"
                            st.markdown(f"**{i}. ğŸ“Š Topic Guide** {depth} {next_step}")
                            if details.get("feedback"):
                                st.caption(f"   {details.get('feedback', '')}")
                        
                        # Probing Agent
                        elif node == "probing_agent":
                            st.markdown(f"**{i}. ğŸ” Probing** ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ— â†’ HITL")
                            st.caption(f"   ãƒˆãƒ”ãƒƒã‚¯: {details.get('topic', 'N/A')}")
                        
                        # Topic Agent
                        elif node == "topic_agent":
                            st.markdown(f"**{i}. ğŸ¯ Topic Agent** æ–°ã—ã„è³ªå• â†’ HITL")
                            st.caption(f"   ãƒˆãƒ”ãƒƒã‚¯: {details.get('topic', 'N/A')}")
                        
                        # Next Topic
                        elif node == "next_topic":
                            st.markdown(f"**{i}. â¡ï¸ æ¬¡ã®ãƒˆãƒ”ãƒƒã‚¯** â†’ Topic Agent")
                        
                        # Human Input Node
                        elif node == "human_input_node":
                            st.markdown(f"**{i}. ğŸ‘¤ HITL** ä¸­æ–­ â†’ Security")
                    
                    # ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªçŠ¶æ…‹ã‚µãƒãƒªãƒ¼
                    st.caption(f"çŠ¶æ…‹: ãƒˆãƒ”ãƒƒã‚¯ {message.get('topic_index', 0)} | ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {message.get('topic_iteration', 0)} | Judgeå†è©¦è¡Œ {message.get('judge_retries', 0)}")
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if user_input := st.chat_input("ã“ã¡ã‚‰ã«å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        
        # åŒã˜å…¥åŠ›ã®é‡è¤‡å‡¦ç†ã‚’é˜²ã
        if st.session_state.last_processed_input == user_input:
            # ã“ã®å…¥åŠ›ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã€ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã«ã‚¹ã‚­ãƒƒãƒ—
            st.stop()
        
        # æ—¢ã«å‡¦ç†ä¸­ã‹ãƒã‚§ãƒƒã‚¯
        if st.session_state.processing:
            # åˆ¥ã®å…¥åŠ›ã‚’æ—¢ã«å‡¦ç†ä¸­ã€ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã«ã‚¹ã‚­ãƒƒãƒ—
            st.stop()
        
        # æœ€åˆã«å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
        st.session_state.processing = True
        st.session_state.last_processed_input = user_input
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆã«è¿½åŠ 
        st.session_state.messages.append({
            "role": "user",
            "content": user_input
        })
        
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã§çŠ¶æ…‹ã‚’æ›´æ–°
        st.session_state.state["user_answer"] = user_input
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ°¸ç¶šåŒ–ç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰è¨­å®š
        config = {"configurable": {"thread_id": st.session_state.session_id}}
        
        st.session_state.graph.update_state(
            config,
            {"user_answer": user_input},
            as_node="human_input_node"  # human_input_nodeãŒç”Ÿæˆã—ãŸã‹ã®ã‚ˆã†ã«æ›´æ–°
        )
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã§ã‚°ãƒ©ãƒ•ã‚’ä¸­æ–­ã‹ã‚‰å†é–‹
        # ã‚°ãƒ©ãƒ•ã¯ç¶šè¡Œ: human_input_node â†’ security_agent â†’ ...
        # æ¬¡ã®ä¸­æ–­ï¼ˆå†ã³human_input_nodeï¼‰ã¾ãŸã¯ENDï¼ˆfeedback_agentï¼‰ã«åˆ°é”ã™ã‚‹ã¾ã§
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚’è¿½è·¡
        execution_log = []
        
        with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ä¸­..."):
            # Noneã¨configã§invokeã‚’å‘¼ã³å‡ºã—ä¸­æ–­ã‹ã‚‰å†é–‹
            # ã“ã‚Œã¯LangGraphã«ã€Œä¸­æ–­ã—ãŸå ´æ‰€ã‹ã‚‰ç¶šã‘ã‚‹ã€ã¨ä¼ãˆã¾ã™
            for chunk in st.session_state.graph.stream(None, config):
                # å„ãƒãƒ¼ãƒ‰ã®å‡ºåŠ›ã‚’å‡¦ç†
                for node_name, node_output in chunk.items():
                    # node_outputã¯è¾æ›¸ã§ã‚ã‚‹ã¹ãã§ã™ãŒã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’å‡¦ç†
                    if not isinstance(node_output, dict):
                        continue
                    
                    st.session_state.state.update(node_output)
                    
                    # å®Ÿè¡Œã®è©³ç´°ã‚’ãƒ­ã‚°
                    log_entry = {
                        "node": node_name,
                        "agent": node_output.get("current_agent", ""),
                        "details": {}
                    }
                    
                    # Security agentã®è©³ç´°
                    if node_name == "security_agent":
                        log_entry["details"] = {
                            "passed": node_output.get("security_passed"),
                            "feedback": node_output.get("security_feedback", ""),
                            "answer_length": len(st.session_state.state.get("user_answer", "")),
                        }
                    
                    # Judge agentã®è©³ç´°
                    elif node_name == "judge":
                        log_entry["details"] = {
                            "retry_count": node_output.get("judge_retry_count", 0),
                            "max_retries": st.session_state.state.get("max_judge_retries", 0),
                            "action": "requesting retry" if node_output.get("waiting_for_user_input") else "giving up"
                        }
                    
                    # Topic guideã®è©³ç´°
                    elif node_name == "topic_guide":
                        log_entry["details"] = {
                            "depth_sufficient": node_output.get("topic_depth_sufficient"),
                            "iteration": st.session_state.state.get("topic_iteration_count", 0),
                            "max_iterations": st.session_state.state.get("max_iterations_per_topic", 0),
                            "feedback": node_output.get("topic_feedback", ""),
                        }
                    
                    # Topic/Probing agentã®è©³ç´°
                    elif node_name in ["topic_agent", "probing_agent"]:
                        log_entry["details"] = {
                            "question_generated": bool(node_output.get("current_question")),
                            "topic": st.session_state.state.get("current_topic", {}).get("topic", ""),
                            "theme": st.session_state.state.get("current_topic", {}).get("theme", ""),
                        }
                    
                    execution_log.append(log_entry)
            
            # ã‚°ãƒ©ãƒ•ã¯ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã«åˆ°é”:
            # 1. æ¬¡ã®ä¸­æ–­ï¼ˆhuman_input_nodeï¼‰ - æ–°ã—ã„è³ªå•ã®æº–å‚™å®Œäº†
            # 2. ENDï¼ˆfeedback_agentï¼‰ - é¢æ¥å®Œäº†
            
            # æ–°ã—ã„è³ªå•/ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒç”Ÿæˆã•ã‚ŒãŸå ´åˆã¯è¡¨ç¤º
            if st.session_state.state.get("current_question"):
                agent_name = st.session_state.state.get("current_agent", "Agent")
                tokens = st.session_state.state.get("last_message_tokens", 0)
                
                if st.session_state.state.get("interview_complete"):
                    # Feedback agent - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒšãƒ¼ã‚¸ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ä¿å­˜
                    st.session_state.feedback = st.session_state.state["current_question"]
                    st.session_state.feedback_tokens = tokens
                    st.session_state.interview_ended = True
                    
                    # é¢æ¥å®Œäº†ã®ãƒ­ã‚°
                    if st.session_state.logger:
                        total_questions = len([m for m in st.session_state.messages if m["role"] == "assistant"])
                        st.session_state.logger.log_interview_complete(
                            st.session_state.state["current_topic_index"],
                            total_questions
                        )
                else:
                    # ãƒãƒ£ãƒƒãƒˆã«è³ªå•ã‚’è¡¨ç¤ºï¼ˆjudge/probing/topic agentï¼‰
                    agent_message = {
                        "role": "assistant",
                        "content": st.session_state.state["current_question"],
                        "agent": agent_name,
                        "tokens": tokens,
                        "execution_log": execution_log,  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨å…±ã«å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜
                        "topic_index": st.session_state.state.get("current_topic_index", 0),
                        "topic_iteration": st.session_state.state.get("topic_iteration_count", 0),
                        "judge_retries": st.session_state.state.get("judge_retry_count", 0)
                    }
                    st.session_state.messages.append(agent_message)
                    
                    with st.chat_message("assistant"):
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.caption(f"{agent_name}")
                        with col2:
                            st.caption(f"ğŸª™ {tokens} tokens")
                        st.markdown(st.session_state.state["current_question"])
        
        # å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state.processing = False
        st.rerun()

elif st.session_state.interview_ended:
    st.header("ğŸ“Š é¢æ¥ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
    
    # ã‚°ãƒ©ãƒ•ã®feedback_agentã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡¨ç¤º
    if 'feedback' in st.session_state:
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¡¨ç¤º
        st.caption(f"ğŸ“ Feedback Agent | ğŸª™ {st.session_state.get('feedback_tokens', 0)} tokens")
        st.markdown(st.session_state.feedback)
        
        st.divider()
        
        # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ã‚«ãƒãƒ¼ã—ãŸãƒˆãƒ”ãƒƒã‚¯", st.session_state.state["current_topic_index"])
        with col2:
            st.metric("åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³", st.session_state.state.get("total_tokens", 0))
        with col3:
            st.metric("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", len(st.session_state.messages))
        
        st.divider()
        
        # ãƒ­ã‚°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.subheader("ğŸ“¥ é¢æ¥ãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    else:
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œãªã‹ã£ãŸ
        st.error("âš ï¸ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚è©³ç´°ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.info("é¢æ¥ã¯çµ‚äº†ã—ã¾ã—ãŸãŒã€Feedback AgentãŒå‡ºåŠ›ã‚’ç”Ÿæˆã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä¼šè©±å±¥æ­´ã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã‚‹
        if st.session_state.state and "conversation_history" in st.session_state.state:
            for entry in reversed(st.session_state.state["conversation_history"]):
                if entry.get("agent") == "feedback_agent" and "feedback" in entry:
                    st.session_state.feedback = entry["feedback"]
                    st.session_state.feedback_tokens = entry.get("tokens", 0)
                    st.success("âœ… ä¼šè©±å±¥æ­´ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¾©å…ƒã—ã¾ã—ãŸï¼")
                    st.markdown(st.session_state.feedback)
                    break
        
        if st.session_state.logger:
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’æä¾›ã™ã‚‹å‰ã«ãƒ­ã‚°ã‚’ä¿å­˜
            st.session_state.logger.save()
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                conversation_text = st.session_state.logger.export_conversation_text()
                st.download_button(
                    label="ğŸ“„ ä¼šè©±ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=conversation_text,
                    file_name=f"conversation_{st.session_state.session_id}.txt",
                    mime="text/plain"
                )
            
            with col2:
                # å®Œå…¨ãªJSONãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                import json
                json_data = json.dumps(st.session_state.logger.log_data, indent=2, ensure_ascii=False)
                st.download_button(
                    label="ğŸ“Š å®Œå…¨ãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (JSON)",
                    data=json_data,
                    file_name=f"interview_{st.session_state.session_id}.json",
                    mime="application/json"
                )
            
            with col3:
                # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€ã‚’è¡¨ç¤º
                st.info(f"ãƒ­ã‚°ã®ä¿å­˜å…ˆ:\n`{st.session_state.logger.log_dir}`")
    
    if st.button("æ–°ã—ã„é¢æ¥ã‚’é–‹å§‹", type="primary"):
        # ãƒ­ã‚¬ãƒ¼ã‚’ä¿å­˜ã—ã¦ã‚¯ãƒªã‚¢
        if st.session_state.logger:
            st.session_state.logger.save()
            clear_logger()
        
        st.session_state.interview_started = False
        st.session_state.session_id = None
        st.session_state.messages = []
        st.session_state.interview_ended = False
        st.session_state.state = None
        st.session_state.graph = None
        st.session_state.logger = None
        if 'feedback' in st.session_state:
            del st.session_state.feedback
        if 'feedback_tokens' in st.session_state:
            del st.session_state.feedback_tokens
        st.rerun()

else:
    # ã‚¦ã‚§ãƒ«ã‚«ãƒ ç”»é¢
    st.markdown("""
    ## å¾“æ¥­å“¡çŸ¥è­˜è©•ä¾¡é¢æ¥ã¸ã‚ˆã†ã“ãï¼ ğŸ‘‹
    
    ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ä¼æ¥­çŸ¥è­˜ã«é–¢ã™ã‚‹è©³ç´°ãªé¢æ¥ã‚’å®Ÿæ–½ã™ã‚‹**ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ **ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
    
    ### ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ :
    - ğŸ¯ **Topic Agent**: äº‹å‰å®šç¾©ã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ã‹ã‚‰è³ªå•ã‚’ç”Ÿæˆ
    - ğŸ”’ **Security Agent**: å›ç­”ã®å“è³ªã¨é–¢é€£æ€§ã‚’æ¤œè¨¼
    - âš–ï¸ **Judge Agent**: ä¸æ˜ç­ãªå›ç­”ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›
    - ğŸ“Š **Topic Guide**: çŸ¥è­˜ã®æ·±ã•ã‚’è©•ä¾¡
    - ğŸ” **Probing Agent**: ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•ã‚’å®Ÿæ–½
    - ğŸ“ **Feedback Agent**: åŒ…æ‹¬çš„ãªè©•ä¾¡ã‚’æä¾›
    
    ### ä½¿ã„æ–¹:
    1. **ãƒˆãƒ”ãƒƒã‚¯CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**ï¼ˆã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ï¼‰ãƒ†ãƒ¼ãƒã¨ä¾‹ç¤ºè³ªå•ã‚’å«ã‚€
    2. **é¢æ¥ã‚’é–‹å§‹** - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä¼šè©±ã‚’ã‚¬ã‚¤ãƒ‰
    3. **è³ªå•ã«å›ç­”** - ã©ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¿œç­”ã—ã¦ã„ã‚‹ã‹ã€ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’ç¢ºèª
    4. **ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘å–ã‚‹** - ãƒ†ãƒ¼ãƒåˆ¥ã®åŒ…æ‹¬çš„ãªè©•ä¾¡
    
    ### æ©Ÿèƒ½:
    - âœ… å„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè­˜åˆ¥
    - âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡è¿½è·¡
    - âœ… ãƒˆãƒ”ãƒƒã‚¯å…¨ä½“ã®é€²æ—è¿½è·¡
    - âœ… ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•
    - âœ… ãƒ†ãƒ¼ãƒåˆ¥ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
    
    **å§‹ã‚ã‚‹æº–å‚™ã¯ã§ãã¾ã—ãŸã‹ï¼Ÿ** ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§é¢æ¥ã‚’è¨­å®šã—ã€ã€Œé¢æ¥ã‚’é–‹å§‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ï¼
    """)
