import streamlit as st
from datetime import datetime
from pathlib import Path
from core import create_interview_graph
from core.utils import load_topics_from_csv
from interview_logging.interview_logger import InterviewLogger, set_logger, clear_logger, get_logger
from management.prompt_manager import PromptManager, get_prompt_manager
import os
import pandas as pd
from streamlit_extras.bottom_container import bottom


# Streamlit UI
st.set_page_config(page_title="AIé¢æ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", page_icon="ğŸ’¼", layout="wide")

st.title("ğŸ’¼ å¾“æ¥­å“¡çŸ¥è­˜è©•ä¾¡é¢æ¥")
st.markdown("ä¼æ¥­ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹å¾“æ¥­å“¡ã®çŸ¥è­˜ã‚’è©•ä¾¡ã™ã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'interview_started' not in st.session_state:
    st.session_state.interview_started = False
if 'session_id' not in st.session_state:
    st.session_state.session_id = None
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'interview_ended' not in st.session_state:
    st.session_state.interview_ended = False
if 'state' not in st.session_state:
    st.session_state.state = None
if 'graph' not in st.session_state:
    st.session_state.graph = None
if 'logger' not in st.session_state:
    st.session_state.logger = None
if 'last_processed_input' not in st.session_state:
    st.session_state.last_processed_input = None
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'feedback' not in st.session_state:
    st.session_state.feedback = None
if 'feedback_tokens' not in st.session_state:
    st.session_state.feedback_tokens = 0
if 'execution_logs' not in st.session_state:
    st.session_state.execution_logs = []  # å„å¿œç­”ã®å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜

# éŸ³å£°å…¥åŠ›ã®çŠ¶æ…‹åˆæœŸåŒ–
if 'voice_recording' not in st.session_state:
    st.session_state.voice_recording = False
if 'voice_transcription' not in st.session_state:
    st.session_state.voice_transcription = ""
if 'voice_temp_text' not in st.session_state:
    st.session_state.voice_temp_text = ""
if 'pending_voice_input' not in st.session_state:
    st.session_state.pending_voice_input = None

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("é¢æ¥è¨­å®š")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åå…¥åŠ›
    st.subheader("ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±")
    username = st.text_input(
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼å",
        value=st.session_state.get('username', ''),
        placeholder="ä¾‹: tanaka_taro",
        help="ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è­˜åˆ¥ã«ä½¿ç”¨ã•ã‚Œã¾ã™",
        key="username_input"
    )
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’ä¿å­˜
    if username:
        st.session_state.username = username
    
    st.divider()
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
    st.subheader("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š")
    
    pm = get_prompt_manager()
    available_prompts = PromptManager.list_available_prompts()
    
    if available_prompts:
        # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
        current_file = str(pm.config_path)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        prompt_options = {p['file']: p for p in available_prompts}
        prompt_files = list(prompt_options.keys())
        
        # ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        current_filename = Path(current_file).name
        try:
            current_index = prompt_files.index(current_filename)
        except ValueError:
            current_index = 0
        
        # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
        selected_file = st.selectbox(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            options=prompt_files,
            index=current_index,
            key="prompt_file_selector"
        )
        
        # é¸æŠã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æƒ…å ±ã‚’è¡¨ç¤º
        selected_info = prompt_options[selected_file]
        
        # ãƒ¡ãƒ¢ã‚’è¡¨ç¤º
        if selected_info['memo']:
            st.info(f"**ğŸ“Œ èª¬æ˜**\n\n{selected_info['memo']}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒªãƒ­ãƒ¼ãƒ‰
        if selected_file != current_filename:
            try:
                pm.load_from_file(selected_info['path'])
                st.success(f"âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ **{selected_file}** ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")
                st.rerun()  # æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åæ˜ ã™ã‚‹ãŸã‚ã«å†èª­ã¿è¾¼ã¿
            except Exception as e:
                st.error(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    else:
        st.warning("âš ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    st.divider()
    
    if not st.session_state.interview_started:
        # LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®è¡¨ç¤º
        llm_provider = os.getenv("LLM_PROVIDER", "openai").upper()
        st.info(f"ğŸ¤– LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: **{llm_provider}**")
        
        # ãƒˆãƒ”ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠ
        data_dir = Path("data")
        if data_dir.exists():
            available_files = sorted([f.name for f in data_dir.glob("*.csv")])
            if available_files:
                topics_file_name = st.selectbox(
                    "ãƒˆãƒ”ãƒƒã‚¯CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                    options=available_files,
                    key="topics_file_selector"
                )
                topics_file = str(data_dir / topics_file_name)
            else:
                st.warning("âš ï¸ data/ ãƒ•ã‚©ãƒ«ãƒ€ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                topics_file = "data/topics.csv"
        else:
            st.warning("âš ï¸ data/ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            topics_file = "data/topics.csv"
        
        if os.path.exists(topics_file):
            topics = load_topics_from_csv(topics_file)
            st.success(f"âœ… {len(topics)}ä»¶ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        else:
            st.warning("âš ï¸ ãƒˆãƒ”ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            topics = load_topics_from_csv(topics_file)
        
        max_iterations = st.number_input("ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã®æœ€å¤§ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—æ•°", min_value=1, max_value=10, value=2, step=1)
        max_judge_retries = st.number_input("Judge Agentã®æœ€å¤§å†è©¦è¡Œå›æ•°", min_value=0, max_value=10, value=2, step=1,
                                            help="ç„¡åŠ¹ãªå›ç­”ã«å¯¾ã—ã¦Judge AgentãŒå†è©¦è¡Œã‚’æ±‚ã‚ã‚‹å›æ•°ã€‚0ã«è¨­å®šã™ã‚‹ã¨æ¬¡ã®è³ªå•ã«ç›´æ¥ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        
        if st.button("é¢æ¥ã‚’é–‹å§‹", type="primary"):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            if not st.session_state.get('username'):
                st.error("âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                st.stop()
            
            with st.spinner("ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­..."):
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã¨ã—ã¦ä¸€æ„ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆ
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                username_prefix = st.session_state.username.replace(' ', '_').replace('/', '_').replace('\\', '_')
                st.session_state.session_id = f"{username_prefix}-{timestamp}"
                
                # ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
                st.session_state.logger = InterviewLogger(st.session_state.session_id)
                set_logger(st.session_state.logger)
                st.session_state.logger.text_logger.info("Interview session initialized")
                
                # Log configuration files being used
                st.session_state.logger.set_prompt_file(str(pm.config_path))
                st.session_state.logger.set_topic_file(topics_file)
                
                # çŠ¶æ…‹ã®åˆæœŸåŒ–
                st.session_state.state = {
                    "topics": topics,
                    "current_topic_index": 0,
                    "current_topic": {},
                    "topic_iteration_count": 0,
                    "max_iterations_per_topic": max_iterations,
                    "judge_retry_count": 0,
                    "max_judge_retries": max_judge_retries,
                    "current_question": "",
                    "user_answer": "",
                    "security_passed": False,
                    "security_feedback": "",
                    "topic_depth_sufficient": False,
                    "topic_feedback": "",
                    "interview_complete": False,
                    "conversation_history": [],
                    "final_feedback": "",
                    "current_agent": "",
                    "total_tokens": 0,
                    "last_message_tokens": 0,
                    "waiting_for_user_input": False  # ä¸­æ–­ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ç½®ãæ›ãˆã‚‰ã‚Œã¾ã™
                }
                
                # ä¸­æ–­ç”¨ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ã‚¿ãƒ¼ä»˜ãã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
                st.session_state.graph = create_interview_graph()
                
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ°¸ç¶šåŒ–ç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰è¨­å®š
                config = {"configurable": {"thread_id": st.session_state.session_id}}
                
                # ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œã‚’é–‹å§‹ - HITLï¼ˆä¸­æ–­ï¼‰ã«åˆ°é”ã™ã‚‹ã¾ã§å®Ÿè¡Œ
                # ã‚°ãƒ©ãƒ•ãƒ•ãƒ­ãƒ¼: START â†’ topic_agent â†’ human_input_node (INTERRUPT)
                for chunk in st.session_state.graph.stream(st.session_state.state, config):
                    # å„ãƒãƒ¼ãƒ‰ã®å‡ºåŠ›ã‚’å‡¦ç†
                    for node_name, node_output in chunk.items():
                        st.session_state.state.update(node_output)
                
                # ã“ã®æ™‚ç‚¹ã§ã€ã‚°ãƒ©ãƒ•ã¯human_input_nodeã§ä¸­æ–­ã•ã‚Œã¦ã„ã¾ã™
                # æœ€åˆã®è³ªå•ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™
                
                # æœ€åˆã®è³ªå•ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                if st.session_state.state.get("current_question"):
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": st.session_state.state["current_question"],
                        "agent": st.session_state.state.get("current_agent", "Topic Agent"),
                        "tokens": st.session_state.state.get("last_message_tokens", 0)
                    })
                
                st.session_state.interview_started = True
                st.rerun()
    
    else:
        st.success("âœ… é¢æ¥é€²è¡Œä¸­")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®è¡¨ç¤º
        if st.session_state.get('username'):
            st.info(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: **{st.session_state.username}**")
        
        # é€²æ—çŠ¶æ³ã®è¡¨ç¤º
        if st.session_state.state:
            current_idx = st.session_state.state["current_topic_index"]
            total_topics = len(st.session_state.state["topics"])
            st.progress((current_idx + 1) / total_topics)
            st.write(f"ãƒˆãƒ”ãƒƒã‚¯ {current_idx + 1} / {total_topics}")
            
            if st.session_state.state.get("current_topic"):
                st.info(f"**ç¾åœ¨ã®ãƒˆãƒ”ãƒƒã‚¯:**\n{st.session_state.state['current_topic'].get('topic', 'N/A')}")
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡
            total_tokens = st.session_state.state.get("total_tokens", 0)
            st.metric("ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³åˆè¨ˆ", total_tokens)
        
        st.divider()
        
        # é¢æ¥çµ‚äº†ãƒœã‚¿ãƒ³ã¯ã€ã¾ã çµ‚äº†ã—ã¦ã„ãªã„&ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆä¸­ã§ãªã„å ´åˆã®ã¿è¡¨ç¤º
        if not st.session_state.interview_ended and not st.session_state.get('generating_feedback', False):
            if st.button("é¢æ¥ã‚’çµ‚äº†ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—", type="secondary", key="end_interview_btn"):
                # å‡¦ç†å‰ã«çŠ¶æ…‹ã‚’å†ç¢ºèªï¼ˆç«¶åˆçŠ¶æ…‹ã‚’é˜²ãï¼‰
                if st.session_state.interview_ended or st.session_state.get('generating_feedback', False) or st.session_state.get('feedback'):
                    st.rerun()
                    
                st.session_state.generating_feedback = True
                
                try:
                    with st.spinner("åŒ…æ‹¬çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆä¸­..."):
                        # ãƒ‡ãƒãƒƒã‚°ç”¨ã®ãƒ­ã‚°
                        if st.session_state.logger:
                            st.session_state.logger.text_logger.info("Button clicked: End Interview & Get Feedback")
                        
                        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰è¨­å®š
                        config = {"configurable": {"thread_id": st.session_state.session_id}}
                        
                        # ã‚°ãƒ©ãƒ•ãŒä¸­æ–­å¯èƒ½ãªçŠ¶æ…‹ã‹ãƒã‚§ãƒƒã‚¯
                        try:
                            snapshot = st.session_state.graph.get_state(config)
                            # æ¬¡ã®ãƒãƒ¼ãƒ‰ãƒªã‚¹ãƒˆãŒç©ºã®å ´åˆã€ã‚°ãƒ©ãƒ•ã¯æ—¢ã«å®Œäº†ã—ã¦ã„ã¾ã™
                            if not snapshot.next:
                                if st.session_state.logger:
                                    st.session_state.logger.text_logger.warning("Graph already at END state, cannot resume")
                                st.session_state.generating_feedback = False
                                st.rerun()
                        except Exception as e:
                            if st.session_state.logger:
                                st.session_state.logger.text_logger.error(f"Error checking graph state: {e}")
                        
                        # é‡è¦: ã‚°ãƒ©ãƒ•çŠ¶æ…‹ã«interview_completeãƒ•ãƒ©ã‚°ã‚’è¨­å®š
                        # æœ€é©åŒ–: security â†’ topic_guideã‚’çµŒç”±ã›ãšã€
                        # interview_complete=Trueã§topic_guideã‹ã‚‰æ¥ãŸã‚ˆã†ã«çŠ¶æ…‹ã‚’æ›´æ–°
                        # ã“ã‚Œã«ã‚ˆã‚Štopic_guideã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒã™ãã«ãƒ•ãƒ©ã‚°ã‚’ç¢ºèªã—ã¦feedback_agentã«é€²ã¿ã¾ã™
                        
                        # ã¾ãšã€é‡è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¿æŒã™ã‚‹ãŸã‚ã«ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—
                        current_snapshot = st.session_state.graph.get_state(config)
                        current_values = current_snapshot.values
                        
                        # topic_guideãƒãƒ¼ãƒ‰ã¨ã—ã¦å‹•ä½œã—ã€interview_completeãƒ•ãƒ©ã‚°ã§çŠ¶æ…‹ã‚’æ›´æ–°
                        st.session_state.graph.update_state(
                            config,
                            {
                                "interview_complete": True,
                                "topic_depth_sufficient": False,  # interview_completeãŒå„ªå…ˆã•ã‚Œã‚‹ã®ã§é–¢ä¿‚ã‚ã‚Šã¾ã›ã‚“
                                "user_answer": current_values.get("user_answer", ""),  # æ—¢å­˜ã®å›ç­”ã‚’ä¿æŒ
                            },
                            as_node="topic_guide"  # topic_guideãŒè©•ä¾¡ã‚’çµ‚ãˆãŸã‹ã®ã‚ˆã†ã«å‹•ä½œ
                        )
                        
                        # topic_guideã‹ã‚‰å†é–‹ - feedback_agentã«ç›´æ¥ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
                        for chunk in st.session_state.graph.stream(None, config):
                            for node_name, node_output in chunk.items():
                                if isinstance(node_output, dict):
                                    st.session_state.state.update(node_output)
                                    
                                    # feedback_agentã«åˆ°é”ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                                    if node_output.get("current_agent") == "Feedback Agent" or node_name == "feedback_agent":
                                        # ã™ãã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æŠ½å‡º
                                        if node_output.get("final_feedback"):
                                            st.session_state.feedback = node_output["final_feedback"]
                                            st.session_state.feedback_tokens = node_output.get("last_message_tokens", 0)
                                            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                                            break
                        
                        if st.session_state.logger:
                            st.session_state.logger.text_logger.info("Graph stream completed successfully")
                        
                        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæŠ½å‡ºã•ã‚ŒãŸã‹ç¢ºèª
                        if not st.session_state.get('feedback'):
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€çµ‚çŠ¶æ…‹ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
                            if st.session_state.state.get("final_feedback"):
                                st.session_state.feedback = st.session_state.state["final_feedback"]
                                st.session_state.feedback_tokens = st.session_state.state.get("last_message_tokens", 0)
                            else:
                                st.session_state.feedback = "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                                st.session_state.feedback_tokens = 0
                        
                        # é¢æ¥å®Œäº†ã®ãƒ­ã‚°
                        if st.session_state.logger and st.session_state.get('feedback'):
                            total_questions = len([m for m in st.session_state.messages if m["role"] == "assistant"])
                            st.session_state.logger.log_interview_complete(
                                st.session_state.state["current_topic_index"],
                                total_questions
                            )
                        
                        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚ŒãŸå ´åˆã®ã¿çµ‚äº†ã¨ãƒãƒ¼ã‚¯
                        if st.session_state.get('feedback'):
                            st.session_state.interview_ended = True
                        
                finally:
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ•ãƒ©ã‚°ã‚’å¸¸ã«ã‚¯ãƒªã‚¢
                    st.session_state.generating_feedback = False
                    
                st.rerun()
        elif st.session_state.get('generating_feedback', False):
            st.info("â³ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
        
        if st.button("é¢æ¥ã‚’ãƒªã‚»ãƒƒãƒˆ", type="primary"):
            # ãƒªã‚»ãƒƒãƒˆå‰ã«ãƒ­ã‚¬ãƒ¼ã‚’ä¿å­˜ã—ã¦ã‚¯ãƒªã‚¢
            if st.session_state.logger:
                st.session_state.logger.save()
                clear_logger()
            
            st.session_state.interview_started = False
            st.session_state.session_id = None
            st.session_state.messages = []
            st.session_state.interview_ended = False
            st.session_state.state = None
            st.session_state.graph = None
            st.session_state.logger = None
            if 'feedback' in st.session_state:
                del st.session_state.feedback
            st.rerun()

# ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
if st.session_state.interview_started and not st.session_state.interview_ended:
    # ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
            if message["role"] == "assistant" and "agent" in message:
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.caption(f"{message['agent']}")
                with col2:
                    st.caption(f"ğŸª™ {message.get('tokens', 0)} tokens")
            
            st.markdown(message["content"])
            
            # å®Ÿè¡Œãƒ­ã‚°ã®ã‚ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ‡ãƒãƒƒã‚°ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã‚’è¡¨ç¤º
            if message["role"] == "assistant" and "execution_log" in message:
                execution_log = message["execution_log"]
                
                with st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°: Agent Flow", expanded=False):
                    for i, log in enumerate(execution_log, 1):
                        node = log["node"]
                        agent = log["agent"]
                        details = log["details"]
                        
                        # Security Agent
                        if node == "security_agent":
                            status = "âœ… åˆæ ¼" if details.get("passed") else "âŒ ä¸åˆæ ¼"
                            next_step = "â†’ Topic Guide" if details.get("passed") else "â†’ Judge"
                            st.markdown(f"**{i}. ğŸ”’ Security** {status} {next_step}")
                            if not details.get("passed"):
                                st.caption(f"   ç†ç”±: {details.get('feedback', 'N/A')}")
                        
                        # Judge Agent
                        elif node == "judge":
                            action = "å†è©¦è¡Œ" if details.get('action') == 'requesting retry' else "è«¦ã‚ã‚‹"
                            next_step = "â†’ HITL" if details.get('action') == 'requesting retry' else "â†’ Topic Guide"
                            st.markdown(f"**{i}. âš–ï¸ Judge** {action} ({details.get('retry_count', 0)}/{details.get('max_retries', 0)}) {next_step}")
                        
                        # Topic Guide
                        elif node == "topic_guide":
                            depth = "âœ… ååˆ†" if details.get("depth_sufficient") else "âŒ ä¸è¶³"
                            if details.get("depth_sufficient"):
                                next_step = "â†’ æ¬¡ã®ãƒˆãƒ”ãƒƒã‚¯" if details.get('iteration', 0) < details.get('max_iterations', 0) else "â†’ Feedback"
                            else:
                                next_step = "â†’ Probing"
                            st.markdown(f"**{i}. ğŸ“Š Topic Guide** {depth} {next_step}")
                            if details.get("feedback"):
                                st.caption(f"   {details.get('feedback', '')}")
                        
                        # Probing Agent
                        elif node == "probing_agent":
                            st.markdown(f"**{i}. ğŸ” Probing** ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ— â†’ HITL")
                            st.caption(f"   ãƒˆãƒ”ãƒƒã‚¯: {details.get('topic', 'N/A')}")
                        
                        # Topic Agent
                        elif node == "topic_agent":
                            st.markdown(f"**{i}. ğŸ¯ Topic Agent** æ–°ã—ã„è³ªå• â†’ HITL")
                            st.caption(f"   ãƒˆãƒ”ãƒƒã‚¯: {details.get('topic', 'N/A')}")
                        
                        # Next Topic
                        elif node == "next_topic":
                            st.markdown(f"**{i}. â¡ï¸ æ¬¡ã®ãƒˆãƒ”ãƒƒã‚¯** â†’ Topic Agent")
                        
                        # Human Input Node
                        elif node == "human_input_node":
                            st.markdown(f"**{i}. ğŸ‘¤ HITL** ä¸­æ–­ â†’ Security")
                    
                    # ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªçŠ¶æ…‹ã‚µãƒãƒªãƒ¼
                    st.caption(f"çŠ¶æ…‹: ãƒˆãƒ”ãƒƒã‚¯ {message.get('topic_index', 0)} | ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {message.get('topic_iteration', 0)} | Judgeå†è©¦è¡Œ {message.get('judge_retries', 0)}")
    
    

    # éŸ³å£°å…¥åŠ›UI
    # Check if there's pending voice input to process
    if st.session_state.get('pending_voice_input'):
        user_input = st.session_state.pending_voice_input
        st.session_state.pending_voice_input = None
    else:
        user_input = None
        
    with bottom():
        voice_col1, voice_col2, voice_col3 = st.columns([1, 4, 1])
        
        with voice_col1:
            if st.session_state.voice_recording:
                if st.button("ğŸ›‘ åœæ­¢", key="stop_voice_btn", use_container_width=True, type="secondary"):
                    # Stop recording
                    from voice.voice_input import get_voice_recorder
                    recorder = get_voice_recorder()
                    final_text = recorder.stop_recording()
                    st.session_state.voice_recording = False
                    st.session_state.voice_transcription = final_text
                    st.session_state.voice_temp_text = ""
                    st.session_state.chat_input = final_text
                    st.session_state.duration = round(recorder.duration * 1e-7, 2)
                    
                    st.rerun()
            else:
                if st.button("ğŸ¤ éŸ³å£°", key="start_voice_btn", use_container_width=True):
                    # Start recording
                    from voice.voice_input import get_voice_recorder
                    recorder = get_voice_recorder()
                    
                    if recorder.start_recording():
                        st.session_state.voice_recording = True
                        st.session_state.voice_transcription = ""
                        st.session_state.voice_temp_text = ""
                        st.rerun()
                    else:
                        st.error("éŸ³å£°èªè­˜ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        with voice_col2:
            if st.session_state.voice_recording:
                # Show recording status and live transcription
                # st.markdown("ğŸ”´ **éŒ²éŸ³ä¸­...**")
                # if st.session_state.voice_transcription or st.session_state.voice_temp_text:
                #     current_text = st.session_state.voice_transcription
                #     if st.session_state.voice_temp_text:
                #         current_text = f"{current_text} {st.session_state.voice_temp_text}".strip()
                #     st.caption(f"èªè­˜ä¸­: {current_text}")
                from voice.voice_input import get_voice_recorder
                
                recorder = get_voice_recorder()
                
                # Get current text from thread-safe storage (same singleton instance!)
                temp_text = recorder.get_current_text()
                               
                # Show recording status
                st.markdown("ğŸ”´ **éŒ²éŸ³ä¸­...**")
                
                # Show live transcription if any text is available
                if temp_text:
                    st.caption(f"èªè­˜ä¸­: {temp_text}")
                    
                    # Store in session state for display continuity
                    st.session_state.voice_temp_text = temp_text
                
                # Auto-refresh every 300ms to show live updates
                import time
                time.sleep(0.3)
                st.rerun()
                
            elif st.session_state.voice_transcription:
                # print(f"Recording duration: {recorder.duration} seconds")
                st.caption(f"éŒ²éŸ³æ™‚é–“: {st.session_state.duration} ç§’")
        
        with voice_col3:
            if st.session_state.voice_transcription and not st.session_state.voice_recording:
                if st.button("âœ“ ä½¿ç”¨", key="use_voice_btn", use_container_width=True, type="primary"):
                    # Use the transcription (edited if modified)
                    user_input = st.session_state.get("voice_edit", st.session_state.voice_transcription)
                    st.session_state.voice_transcription = ""
                    st.session_state.voice_temp_text = ""
                    
                    # Process the voice input (same as chat_input processing below)
                    # We'll set a flag and let it be processed below
                    st.session_state.pending_voice_input = user_input
                    st.rerun()
    

    
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    user_input = st.chat_input("ã“ã¡ã‚‰ã«å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...", key="chat_input")
    
    
    # Process user input (from either voice or text)
    if user_input:
        
        # åŒã˜å…¥åŠ›ã®é‡è¤‡å‡¦ç†ã‚’é˜²ã
        if st.session_state.last_processed_input == user_input:
            # ã“ã®å…¥åŠ›ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã€ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã«ã‚¹ã‚­ãƒƒãƒ—
            st.stop()
        
        # æ—¢ã«å‡¦ç†ä¸­ã‹ãƒã‚§ãƒƒã‚¯
        if st.session_state.processing:
            # åˆ¥ã®å…¥åŠ›ã‚’æ—¢ã«å‡¦ç†ä¸­ã€ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã«ã‚¹ã‚­ãƒƒãƒ—
            st.stop()
        
        # æœ€åˆã«å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
        st.session_state.processing = True
        st.session_state.last_processed_input = user_input
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆã«è¿½åŠ 
        st.session_state.messages.append({
            "role": "user",
            "content": user_input
        })
        
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã§çŠ¶æ…‹ã‚’æ›´æ–°
        st.session_state.state["user_answer"] = user_input
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ°¸ç¶šåŒ–ç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰è¨­å®š
        config = {"configurable": {"thread_id": st.session_state.session_id}}
        
        st.session_state.graph.update_state(
            config,
            {"user_answer": user_input},
            as_node="human_input_node"  # human_input_nodeãŒç”Ÿæˆã—ãŸã‹ã®ã‚ˆã†ã«æ›´æ–°
        )
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã§ã‚°ãƒ©ãƒ•ã‚’ä¸­æ–­ã‹ã‚‰å†é–‹
        # ã‚°ãƒ©ãƒ•ã¯ç¶šè¡Œ: human_input_node â†’ security_agent â†’ ...
        # æ¬¡ã®ä¸­æ–­ï¼ˆå†ã³human_input_nodeï¼‰ã¾ãŸã¯ENDï¼ˆfeedback_agentï¼‰ã«åˆ°é”ã™ã‚‹ã¾ã§
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚’è¿½è·¡
        execution_log = []
        
        with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ä¸­..."):
            # Noneã¨configã§invokeã‚’å‘¼ã³å‡ºã—ä¸­æ–­ã‹ã‚‰å†é–‹
            # ã“ã‚Œã¯LangGraphã«ã€Œä¸­æ–­ã—ãŸå ´æ‰€ã‹ã‚‰ç¶šã‘ã‚‹ã€ã¨ä¼ãˆã¾ã™
            for chunk in st.session_state.graph.stream(None, config):
                # å„ãƒãƒ¼ãƒ‰ã®å‡ºåŠ›ã‚’å‡¦ç†
                for node_name, node_output in chunk.items():
                    # node_outputã¯è¾æ›¸ã§ã‚ã‚‹ã¹ãã§ã™ãŒã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’å‡¦ç†
                    if not isinstance(node_output, dict):
                        continue
                    
                    st.session_state.state.update(node_output)
                    
                    # å®Ÿè¡Œã®è©³ç´°ã‚’ãƒ­ã‚°
                    log_entry = {
                        "node": node_name,
                        "agent": node_output.get("current_agent", ""),
                        "details": {}
                    }
                    
                    # Security agentã®è©³ç´°
                    if node_name == "security_agent":
                        log_entry["details"] = {
                            "passed": node_output.get("security_passed"),
                            "feedback": node_output.get("security_feedback", ""),
                            "answer_length": len(st.session_state.state.get("user_answer", "")),
                        }
                    
                    # Judge agentã®è©³ç´°
                    elif node_name == "judge":
                        log_entry["details"] = {
                            "retry_count": node_output.get("judge_retry_count", 0),
                            "max_retries": st.session_state.state.get("max_judge_retries", 0),
                            "action": "requesting retry" if node_output.get("waiting_for_user_input") else "giving up"
                        }
                    
                    # Topic guideã®è©³ç´°
                    elif node_name == "topic_guide":
                        log_entry["details"] = {
                            "depth_sufficient": node_output.get("topic_depth_sufficient"),
                            "iteration": st.session_state.state.get("topic_iteration_count", 0),
                            "max_iterations": st.session_state.state.get("max_iterations_per_topic", 0),
                            "feedback": node_output.get("topic_feedback", ""),
                        }
                    
                    # Topic/Probing agentã®è©³ç´°
                    elif node_name in ["topic_agent", "probing_agent"]:
                        log_entry["details"] = {
                            "question_generated": bool(node_output.get("current_question")),
                            "topic": st.session_state.state.get("current_topic", {}).get("topic", ""),
                            "theme": st.session_state.state.get("current_topic", {}).get("theme", ""),
                        }
                    
                    execution_log.append(log_entry)
            
            # ã‚°ãƒ©ãƒ•ã¯ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã«åˆ°é”:
            # 1. æ¬¡ã®ä¸­æ–­ï¼ˆhuman_input_nodeï¼‰ - æ–°ã—ã„è³ªå•ã®æº–å‚™å®Œäº†
            # 2. ENDï¼ˆfeedback_agentï¼‰ - é¢æ¥å®Œäº†
            
            # é¢æ¥å®Œäº†æ™‚ã¯final_feedbackã‚’ç¢ºèª
            if st.session_state.state.get("interview_complete") and st.session_state.state.get("final_feedback"):
                # Feedback agent - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒšãƒ¼ã‚¸ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ä¿å­˜
                st.session_state.feedback = st.session_state.state["final_feedback"]
                st.session_state.feedback_tokens = st.session_state.state.get("last_message_tokens", 0)
                st.session_state.interview_ended = True
                
                # é¢æ¥å®Œäº†ã®ãƒ­ã‚°
                if st.session_state.logger:
                    total_questions = len([m for m in st.session_state.messages if m["role"] == "assistant"])
                    st.session_state.logger.log_interview_complete(
                        st.session_state.state["current_topic_index"],
                        total_questions
                    )
            # æ–°ã—ã„è³ªå•ãŒç”Ÿæˆã•ã‚ŒãŸå ´åˆã¯è¡¨ç¤º
            elif st.session_state.state.get("current_question"):
                agent_name = st.session_state.state.get("current_agent", "Agent")
                tokens = st.session_state.state.get("last_message_tokens", 0)
                # ãƒãƒ£ãƒƒãƒˆã«è³ªå•ã‚’è¡¨ç¤ºï¼ˆjudge/probing/topic agentï¼‰
                agent_message = {
                    "role": "assistant",
                    "content": st.session_state.state["current_question"],
                    "agent": agent_name,
                    "tokens": tokens,
                    "execution_log": execution_log,  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨å…±ã«å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜
                    "topic_index": st.session_state.state.get("current_topic_index", 0),
                    "topic_iteration": st.session_state.state.get("topic_iteration_count", 0),
                    "judge_retries": st.session_state.state.get("judge_retry_count", 0)
                }
                st.session_state.messages.append(agent_message)
                
                with st.chat_message("assistant"):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.caption(f"{agent_name}")
                    with col2:
                        st.caption(f"ğŸª™ {tokens} tokens")
                    st.markdown(st.session_state.state["current_question"])
        
        # å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state.processing = False
        st.rerun()

elif st.session_state.interview_ended:
    st.header("ğŸ“Š é¢æ¥ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
    
    # ã‚°ãƒ©ãƒ•ã®feedback_agentã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡¨ç¤º
    if 'feedback' in st.session_state:
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¡¨ç¤º
        st.caption(f"ğŸ“ Feedback Agent | ğŸª™ {st.session_state.get('feedback_tokens', 0)} tokens")
        st.markdown(st.session_state.feedback)
        
        st.divider()
        
        # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ã‚«ãƒãƒ¼ã—ãŸãƒˆãƒ”ãƒƒã‚¯", st.session_state.state["current_topic_index"])
        with col2:
            st.metric("åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³", st.session_state.state.get("total_tokens", 0))
        with col3:
            st.metric("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", len(st.session_state.messages))
        
        st.divider()
        
        # ãƒ­ã‚°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.subheader("ğŸ“¥ é¢æ¥ãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    else:
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œãªã‹ã£ãŸ
        st.error("âš ï¸ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚è©³ç´°ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.info("é¢æ¥ã¯çµ‚äº†ã—ã¾ã—ãŸãŒã€Feedback AgentãŒå‡ºåŠ›ã‚’ç”Ÿæˆã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä¼šè©±å±¥æ­´ã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã‚‹
        if st.session_state.state and "conversation_history" in st.session_state.state:
            for entry in reversed(st.session_state.state["conversation_history"]):
                if entry.get("agent") == "feedback_agent" and "feedback" in entry:
                    st.session_state.feedback = entry["feedback"]
                    st.session_state.feedback_tokens = entry.get("tokens", 0)
                    st.success("âœ… ä¼šè©±å±¥æ­´ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¾©å…ƒã—ã¾ã—ãŸï¼")
                    st.markdown(st.session_state.feedback)
                    break
        
        if st.session_state.logger:
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’æä¾›ã™ã‚‹å‰ã«ãƒ­ã‚°ã‚’ä¿å­˜
            st.session_state.logger.save()
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                conversation_text = st.session_state.logger.export_conversation_text()
                st.download_button(
                    label="ğŸ“„ ä¼šè©±ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=conversation_text,
                    file_name=f"conversation_{st.session_state.session_id}.txt",
                    mime="text/plain"
                )
            
            with col2:
                # å®Œå…¨ãªJSONãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                import json
                json_data = json.dumps(st.session_state.logger.log_data, indent=2, ensure_ascii=False)
                st.download_button(
                    label="ğŸ“Š å®Œå…¨ãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (JSON)",
                    data=json_data,
                    file_name=f"interview_{st.session_state.session_id}.json",
                    mime="application/json"
                )
            
            with col3:
                # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€ã‚’è¡¨ç¤º
                st.info(f"ãƒ­ã‚°ã®ä¿å­˜å…ˆ:\n`{st.session_state.logger.log_dir}`")
    
    if st.button("æ–°ã—ã„é¢æ¥ã‚’é–‹å§‹", type="primary"):
        # ãƒ­ã‚¬ãƒ¼ã‚’ä¿å­˜ã—ã¦ã‚¯ãƒªã‚¢
        if st.session_state.logger:
            st.session_state.logger.save()
            clear_logger()
        
        st.session_state.interview_started = False
        st.session_state.session_id = None
        st.session_state.messages = []
        st.session_state.interview_ended = False
        st.session_state.state = None
        st.session_state.graph = None
        st.session_state.logger = None
        if 'feedback' in st.session_state:
            del st.session_state.feedback
        if 'feedback_tokens' in st.session_state:
            del st.session_state.feedback_tokens
        st.rerun()

else:
    # ã‚¦ã‚§ãƒ«ã‚«ãƒ ç”»é¢
    st.markdown("""
    ## ğŸ’¼ å¾“æ¥­å“¡çŸ¥è­˜è©•ä¾¡é¢æ¥ã‚·ã‚¹ãƒ†ãƒ 
    
    ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹å¯¾è©±å‹é¢æ¥ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚æŠ€è¡“çŸ¥è­˜ã‚’æ®µéšçš„ã«è©•ä¾¡ã—ã€è©³ç´°ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ã€‚
    """)
    
    st.divider()
    
    # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### ğŸ“– ãƒšãƒ¼ã‚¸æ§‹æˆ
        
        #### **ğŸ  ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ï¼ˆã“ã®ãƒšãƒ¼ã‚¸ï¼‰**
        ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã‚’è¡Œã„ã€é¢æ¥ã‚’å®Ÿæ–½ã—ã¾ã™ï¼š
        - **ãƒ¦ãƒ¼ã‚¶ãƒ¼å**: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è­˜åˆ¥ç”¨ï¼ˆå¿…é ˆï¼‰- å¾Œã§Log Viewerã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹éš›ã«ä½¿ç”¨
        - **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œã‚’å®šç¾©ã™ã‚‹YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆGraph Prompt Editorã§ä½œæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠå¯èƒ½ï¼‰
        - **ãƒˆãƒ”ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«**: é¢æ¥ã§ä½¿ç”¨ã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆTopic Editorã§ä½œæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠå¯èƒ½ï¼‰
        - **ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—æ•°**: ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã«ä½•å›ã¾ã§æ·±æ˜ã‚Šã™ã‚‹ã‹ï¼ˆ1-10å›ï¼‰
        - **å†è©¦è¡Œå›æ•°**: ä¸é©åˆ‡ãªå›ç­”ã«å¯¾ã—ã¦ä½•å›ã¾ã§å†å›ç­”ã‚’æ±‚ã‚ã‚‹ã‹ï¼ˆ0-10å›ï¼‰
        - **éŸ³å£°å…¥åŠ›å¯¾å¿œ**: ğŸ¤ãƒœã‚¿ãƒ³ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã«ã‚ˆã‚‹å›ç­”ãŒå¯èƒ½
        
        #### **ğŸ“ 02_Graph Prompt Editor**
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼š
        - **6ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å€‹åˆ¥ã«ç·¨é›†ï¼ˆTopic, Security, Judge, Topic Guide, Probing, Feedbackï¼‰
        - **ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢**ã§ç›´æ¥ç·¨é›†ã—ã€å¤‰æ›´å†…å®¹ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        - **ãƒ¡ãƒ¢æ©Ÿèƒ½**ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç›®çš„ãƒ»å¤‰æ›´å±¥æ­´ã‚’è¨˜éŒ²
        - **åˆ¥åä¿å­˜**ã§å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿è­·ã—ãªãŒã‚‰æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œæˆ
        - **å³åº§ã«åæ˜ **: ä¿å­˜å¾Œã€ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠã§åˆ©ç”¨å¯èƒ½
        
        #### **ğŸ“Š 03_Graph Structure**
        é¢æ¥ãƒ•ãƒ­ãƒ¼ã‚’ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã§ç†è§£ï¼š
        - **Mermaidãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ **ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œé †åºã‚’å¯è¦–åŒ–
        - **æ¡ä»¶åˆ†å²**ã®ä»•çµ„ã¿ã‚’å›³ã§ç¢ºèªï¼ˆä¾‹ï¼šSecurityå¤±æ•—â†’Judgeã€Topic Guideä¸è¶³â†’Probingï¼‰
        - **Human-in-the-Loopï¼ˆHITLï¼‰**ã®ä½ç½®ã‚’æŠŠæ¡
        - **ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®æµã‚Œ**ã‚’ç†è§£ã—ã¦ã‹ã‚‰ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºä½œæ¥­ã«ç€æ‰‹
        """)
    
    with col2:
        st.markdown("""
        #### **ğŸ” 04_Log Viewer**
        éå»ã®é¢æ¥ãƒ­ã‚°ã‚’è©³ç´°åˆ†æï¼š
        - **ãƒ¦ãƒ¼ã‚¶ãƒ¼åãƒ•ã‚£ãƒ«ã‚¿**: è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¢æ¥ã‹ã‚‰ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿æŠ½å‡º
        - **ã‚»ãƒƒã‚·ãƒ§ãƒ³é¸æŠ**: æ—¥æ™‚ã¨ãƒˆãƒ”ãƒƒã‚¯æ•°ã§è­˜åˆ¥
        - **ä¼šè©±ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³**: è³ªå•ãƒ»å›ç­”ã‚’æ™‚ç³»åˆ—ã§è¡¨ç¤ºã—ã€ã©ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç™ºè¨€ã—ãŸã‹ç¢ºèª
        - **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¤å®š**: Security/Judge/Topic Guideã®åˆ¤å®šç†ç”±ã¨è©³ç´°ã‚’ç¢ºèª
        - **çµ±è¨ˆæƒ…å ±**: ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã€æ‰€è¦æ™‚é–“ã€ãƒˆãƒ”ãƒƒã‚¯é€²æ—ãªã©ã‚’å¯è¦–åŒ–
        - **ãƒ­ã‚°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã¾ãŸã¯JSONå½¢å¼ã§ä¿å­˜å¯èƒ½
        
        #### **ğŸ“‹ 05_Topic Editor**
        é¢æ¥ãƒˆãƒ”ãƒƒã‚¯ã‚’æŸ”è»Ÿã«ç®¡ç†ï¼š
        - **4ã¤ã®ç·¨é›†ãƒ¢ãƒ¼ãƒ‰**ã‚’åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ï¼ˆTable/Form/Preview/Raw CSVï¼‰
        - **Table Editor**: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆé¢¨ã«ã¾ã¨ã‚ã¦ç·¨é›†ãƒ»è¡Œã®è¿½åŠ å‰Šé™¤
        - **Form Editor**: 1ä»¶ãšã¤ä¸å¯§ã«è¿½åŠ ï¼ˆãƒ†ãƒ¼ãƒã€ãƒˆãƒ”ãƒƒã‚¯ã€ä¾‹ç¤ºè³ªå•ï¼‰
        - **Preview Mode**: ãƒ†ãƒ¼ãƒåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦æ§‹é€ ã‚’ç¢ºèª
        - **Raw CSV Editor**: ç›´æ¥CSVãƒ†ã‚­ã‚¹ãƒˆã‚’ç·¨é›†ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒšã«ä¾¿åˆ©ï¼‰
        - **ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**: å¿…é ˆé …ç›®ãƒã‚§ãƒƒã‚¯ã€é‡è¤‡æ¤œå‡ºã§å“è³ªã‚’ä¿è¨¼
        - **åˆ¥åä¿å­˜**: å…ƒã®topics.csvã‚’ä¸Šæ›¸ãã›ãšã€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        
        ---
        
        ### ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ§‹æˆ
        
        - **ğŸ¯ Topic Agent**: ãƒˆãƒ”ãƒƒã‚¯ã«åŸºã¥ãè³ªå•ã‚’ç”Ÿæˆ
        - **ğŸ”’ Security Agent**: å›ç­”ã®å“è³ªãƒ»é–¢é€£æ€§ã‚’æ¤œè¨¼ï¼ˆçŸ­ã™ãã‚‹/ç„¡é–¢ä¿‚ãªå›ç­”ã‚’æ¤œå‡ºï¼‰
        - **âš–ï¸ Judge Agent**: ä¸ååˆ†ãªå›ç­”ã«æ”¹å–„ã‚’è¦æ±‚ï¼ˆæœ€å¤§å†è©¦è¡Œå›æ•°ã¾ã§ï¼‰
        - **ğŸ“Š Topic Guide**: çŸ¥è­˜ã®æ·±ã•ã‚’è©•ä¾¡ã—ã€ååˆ†ã§ãªã‘ã‚Œã°Probing Agentã¸
        - **ğŸ” Probing Agent**: ã‚ˆã‚Šæ·±ã„ç†è§£ã‚’ç¢ºèªã™ã‚‹ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•ã‚’ç”Ÿæˆ
        - **ğŸ“ Feedback Agent**: å…¨ä½“ã‚’é€šã—ã¦ã®è©³ç´°ãªè©•ä¾¡ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›
        """)
    
    st.divider()
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        ### ğŸš€ ä½¿ã„æ–¹
        
        1. **ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®š**
        - ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å…¥åŠ›ï¼ˆä¾‹ï¼štanaka_taroï¼‰
        - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨å¥¨ï¼‰
        - ãƒˆãƒ”ãƒƒã‚¯CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
        
        2. **ã€Œé¢æ¥ã‚’é–‹å§‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯**
        - Topic AgentãŒæœ€åˆã®è³ªå•ã‚’ç”Ÿæˆ
        - ãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯éŸ³å£°ã§å›ç­”
        
        3. **å¯¾è©±ã‚’ç¶šã‘ã‚‹**
        - Security Agentã¨Judge AgentãŒå›ç­”ã‚’æ¤œè¨¼
        - Topic GuideãŒçŸ¥è­˜ã®æ·±ã•ã‚’è©•ä¾¡
        - Probing AgentãŒãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•ã‚’å®Ÿæ–½
        
        4. **ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—**
        - å…¨ãƒˆãƒ”ãƒƒã‚¯çµ‚äº†å¾Œã€ã¾ãŸã¯é€”ä¸­çµ‚äº†ãƒœã‚¿ãƒ³ã§çµ‚äº†
        - Feedback AgentãŒãƒ†ãƒ¼ãƒåˆ¥ã®ç·åˆè©•ä¾¡ã‚’ç”Ÿæˆ
        - ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½
        
        **ğŸ‘‡ ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§ã§é¢æ¥å†…å®¹ã‚’ç¢ºèªã—ã¦ã‹ã‚‰é–‹å§‹ã—ã¦ãã ã•ã„ï¼**
        """)
    
    # ãƒˆãƒ”ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤º
    with col2:
        st.subheader("ğŸ“‹ ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        
        data_dir = Path("data")
        if data_dir.exists():
            available_files = sorted([f.name for f in data_dir.glob("*.csv")])
            if available_files:
                # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰ï¼‰
                selected_file = st.session_state.get('topics_file_selector')
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨
                if not selected_file:
                    selected_file = "topics.csv" if "topics.csv" in available_files else available_files[0]
                
                topics_preview_file = str(data_dir / selected_file)
                
                if os.path.exists(topics_preview_file):
                    # CSVã‚’DataFrameã¨ã—ã¦èª­ã¿è¾¼ã¿
                    try:
                        df = pd.read_csv(topics_preview_file)
                        st.caption(f"è¡¨ç¤ºä¸­: `{selected_file}` ({len(df)} ãƒˆãƒ”ãƒƒã‚¯)")
                        st.dataframe(df, use_container_width=True, hide_index=True)
                    except Exception as e:
                        st.error(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                else:
                    st.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: `{selected_file}`")
            else:
                st.warning("âš ï¸ data/ ãƒ•ã‚©ãƒ«ãƒ€ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            st.warning("âš ï¸ data/ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

